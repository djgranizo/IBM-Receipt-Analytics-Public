{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Amount Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach:\n",
    "\n",
    "- Step 1: Iterate through Azure analysis JSON Line by line\n",
    "- Step 2: Match line with \"Total\"\n",
    "- Step 3: Determine Total Amount by Iterating through the line\n",
    "    - Approach 1: Create sorted list of lines, Merge lines with enough similarity, estimate Total by going through a line\n",
    "\n",
    "#### Bugs/edgecases to deal with\n",
    "- \"Total\" text and amount found in different lines/regions\n",
    "    - Solution: MergeLines combines lines within a calculated \"slack\" numbre of pixels within eachother\n",
    "- \"Total\" text and amount may not be correctly read by the OCR\n",
    "    - Solution: Apply some text cleaning to increase accuracy\n",
    "- Try to return numbers close to the total\n",
    "    - Solution: using a levenshtein distance (String similarity) of 0.7 if total is not captured subtotal will\n",
    "    - Solution: Iterate from the bottom lines first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import copy\n",
    "from Levenshtein import ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the OCR Analysis JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Punctuation\n",
    "# param text (arr) - Text to Clean\n",
    "def remove_punc(text):\n",
    "    return re.sub(r'[^\\w\\s]','',text)\n",
    "\n",
    "# Remove Digits\n",
    "# param text (str) - Text to clean\n",
    "def remove_digit(text):\n",
    "    return re.sub('\\d+', '',text)\n",
    "\n",
    "\n",
    "# Given an Analysis (JSON) output from Azure OCR, output the lines in order\n",
    "# param: text id (int) - repecetive text id for receipt\n",
    "def extract_lines(text_id):\n",
    "    with open(\"json/\" + str(text_id) + \".txt\",\"r\") as fin:\n",
    "        analysis = json.load(fin)\n",
    "    \n",
    "    unsorted_lines = []\n",
    "    for region in analysis[\"regions\"]:\n",
    "        for line in region[\"lines\"]:\n",
    "            unsorted_lines.append(line)\n",
    "               \n",
    "    # sort by Y coordinates\n",
    "    sorted_lines = sorted(unsorted_lines, key = lambda x: int(x[\"boundingBox\"].split(\",\")[1]))\n",
    "    \n",
    "    return sorted_lines\n",
    "        \n",
    "# Merge word lists in line dictionaries.\n",
    "# Used to merge lines that were not identified in the analysis json\n",
    "# param: line1 - line to merge\n",
    "# param: line2 - line to merge\n",
    "def merge_words(line1,line2):\n",
    "    out_line = line1\n",
    "    out_line[\"words\"] += line2[\"words\"]\n",
    "    return out_line\n",
    "    \n",
    "# Iterate through sorted lines and merging lines that are found to be separate\n",
    "# Lines will be merged if the top edge of the text is within the defined slack\n",
    "# This is used to identify lines that could be angled or shifted as seen below\n",
    "#\n",
    "# Total:\n",
    "#                50.00\n",
    "#\n",
    "# param: sorted_lines (list) - sorted lines output from extract lines\n",
    "# param: slack (int) - the number of pixels above and below the top edge of text \n",
    "#        that will be considered for merging lines\n",
    "def merge_lines(sorted_lines, slack=None):\n",
    "    merged_lines = []\n",
    "    for line_i in sorted_lines:\n",
    "        for line_j in sorted_lines:\n",
    "            line_i_BBy = int(line_i[\"boundingBox\"].split(\",\")[1])\n",
    "            line_j_BBy = int(line_j[\"boundingBox\"].split(\",\")[1])\n",
    "            line_i_BBx = int(line_i[\"boundingBox\"].split(\",\")[0])\n",
    "            line_j_BBx = int(line_j[\"boundingBox\"].split(\",\")[0])\n",
    "            \n",
    "            if slack == None:\n",
    "                slack = int(line_i[\"boundingBox\"].split(\",\")[3]) / 4\n",
    "            \n",
    "            if abs(line_i_BBy - line_j_BBy) < slack and line_i != line_j and line_i_BBx < line_j_BBx:\n",
    "                merge_words(line_i, line_j)\n",
    "                sorted_lines.remove(line_j)\n",
    "                \n",
    "        merged_lines.append(line_i)\n",
    "    return merged_lines\n",
    " \n",
    "# Condensed pipeline of functions to output a final list of text lines\n",
    "# param text_id (int) - id for the desired analysis JSON file\n",
    "def get_lines(text_id):\n",
    "    sorted_lines = extract_lines(text_id)\n",
    "    output = merge_lines(sorted_lines)\n",
    "    return output\n",
    "\n",
    "# Given a line dictionary, iterate through the words for the first number\n",
    "# param line (dict) line dictionary containing word dict\n",
    "def num_search(line):\n",
    "    for word in line[\"words\"]:\n",
    "        test_word = word[\"text\"].replace(\"$\",\"\")\n",
    "        try:\n",
    "            total = float(test_word)\n",
    "            return total\n",
    "        except:\n",
    "            #print(\"searching\")\n",
    "            pass\n",
    "            \n",
    "    #print(\"Could not find total\")\n",
    "    return None\n",
    "\n",
    "# Given a line dictionary, iterate searching for a word similar to \"total\"\n",
    "# param: line (dict) - line dictionary containing words\n",
    "def string_search(line, similarity=0.7):\n",
    "    for word in line[\"words\"]:\n",
    "        test_word = remove_punc(remove_digit(word[\"text\"].lower()))\n",
    "        if ratio(test_word, \"total\") > similarity:\n",
    "            #print(word[\"text\"], test_word, ratio(test_word,\"total\"))\n",
    "            return True\n",
    "        \n",
    "# Final pipeline, Given a text id, collect lines and serach for total amount\n",
    "# param text_id (int) - the id for the json file\n",
    "def extract_total(text_id):\n",
    "    for line in get_lines(text_id)[::-1]:\n",
    "        if string_search(line):\n",
    "            total = num_search(line)\n",
    "            if total is not None:\n",
    "                return total\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
